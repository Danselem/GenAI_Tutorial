{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b0291c",
   "metadata": {},
   "source": [
    "# Arize Phoenix\n",
    "\n",
    "\n",
    "## What is Arize Phoenix?\n",
    "\n",
    "Phoenix is a platform designed to enable observability across every layer of an LLM-based system. It is an open-source observability tool for experimentation, evaluation, and troubleshooting of AI and LLM applications. It allows AI engineers and data scientists to quickly visualize their data, evaluate performance, track down issues, and export data to improve. It supports teams to build, optimize, and maintain high-quality applications and agents efficiently.\n",
    "\n",
    "## Tracing\n",
    "\n",
    "Tracing is a tool for understanding how your LLM application behaves. Phoenix's open-source library offers comprehensive tracing capabilities that are not tied to any specific LLM vendor or framework. :\n",
    "\n",
    "- `Tavily Search`: A search engine designed for AI agents, combining search and scraping capabilities.\n",
    "- `Tavily Extract`: Web Scraping for up to 20 URLs in a single API call.\n",
    "- `Tavily Crawl`: Extensive crawl of multiple domains.\n",
    "\n",
    "## Why Tavily is different\n",
    "\n",
    "Tavily dynamically searches the web, reviews multiple sources, and extracts the most relevant and concise ready-to-use information optimized for AI applications. It focuses on delivering high-quality, customizable search results. Developers control search depth, domain targeting, and content extraction. LLM-generated answers are optional, making Tavily a flexible, search-first solution adaptable to different use cases.\n",
    "\n",
    "<img justify='center' src=\"https://arize.com/docs/phoenix/~gitbook/image?url=https%3A%2F%2Fstorage.googleapis.com%2Farize-assets%2Fphoenix%2Fassets%2Fimages%2Fspan_kinds.png&width=768&dpr=2&quality=100&sign=f3cfa40a&sv=2\" alt=\"Phoenix Tracing Spans\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1941f991",
   "metadata": {},
   "source": [
    "## Phoenix Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e756639",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q arize-phoenix-otel\n",
    "!pip install -q openinference-instrumentation-google-genai\n",
    "!pip install -q openinference-instrumentation-langchain\n",
    "!pip install -q langchain-google-genai\n",
    "!pip install -q openinference-instrumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65745a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from phoenix.otel import register\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a919a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the Environment variables\n",
    "\n",
    "load_dotenv(Path('../../.env'))\n",
    "os.environ[\"PHOENIX_API_KEY\"] = os.getenv(\"PHOENIX_API_KEY\")\n",
    "os.environ[\"PHOENIX_COLLECTOR_ENDPOINT\"] = os.getenv(\"PHOENIX_COLLECTOR_ENDPOINT\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "# os.environ[\"GEMINI_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea7240e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/AI/AI_Tutorial/GenAI_Tutorial/.venv/lib/python3.12/site-packages/phoenix/otel/otel.py:333: UserWarning: Could not infer collector endpoint protocol, defaulting to HTTP.\n",
      "  warnings.warn(\"Could not infer collector endpoint protocol, defaulting to HTTP.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: GOOGLE-llm-app\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: https://app.phoenix.arize.com/s/comradedaniel/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {'authorization': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  ‚ö†Ô∏è WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configure the Phoenix tracer\n",
    "tracer_provider = register(\n",
    "  project_name=\"GOOGLE-llm-app\", # If not defined, will set to Default automatically'\n",
    "  auto_instrument=True,\n",
    ")\n",
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a7ff0",
   "metadata": {},
   "source": [
    "Arize suppports the tracing of popular LLM frameworks. You can view them here: <https://github.com/Arize-ai/openinference?tab=readme-ov-file#instrumentation>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040452f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash-001\")\n",
    "response = chat.send_message(\"What is the capital of the common provinces in South Africa?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e709d814",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d830fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight is white:** Sunlight is actually a mixture of all the colors of the rainbow.\\n\\n*   **Earth's atmosphere:** The Earth is surrounded by an atmosphere containing various gases and particles (mostly nitrogen and oxygen molecules).\\n\\n*   **Scattering:** When sunlight enters the atmosphere, it collides with these air molecules. This collision causes the light to scatter in different directions.\\n\\n*   **Rayleigh scattering:** Rayleigh scattering is a specific type of scattering that is most effective when the size of the particles (air molecules) is much smaller than the wavelength of the light.\\n\\n*   **Wavelength and scattering:** Blue and violet light have shorter wavelengths compared to other colors like red and orange. Rayleigh scattering is much more effective at scattering shorter wavelengths. The amount of scattering is inversely proportional to the fourth power of the wavelength (1/Œª‚Å¥). This means blue light is scattered about 10 times more than red light.\\n\\n*   **Why blue, not violet?** Although violet light has an even shorter wavelength than blue, the sun emits less violet light than blue light. Also, our eyes are more sensitive to blue light. As a result, we perceive the sky as blue.\\n\\n*   **Sunset and sunrise:** When the sun is low on the horizon during sunrise and sunset, the sunlight has to travel through a much greater distance of the atmosphere to reach our eyes. During this longer journey, most of the blue light is scattered away. The remaining light that reaches us is predominantly composed of longer wavelengths like red and orange, resulting in the vibrant colors we see during sunrise and sunset.\\n\\nIn summary, the sky is blue because air molecules scatter blue light from the sun more than they scatter other colors.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run--db7e5c0a-cc97-4d74-9ef7-415f4953934b-0', usage_metadata={'input_tokens': 5, 'output_tokens': 373, 'total_tokens': 378, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{x} {y} {z}?\").partial(x=\"why is\", z=\"blue\")\n",
    "chain = prompt | ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\")\n",
    "chain.invoke(dict(y=\"sky\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f21da",
   "metadata": {},
   "source": [
    "## Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "import google.generativeai as genai\n",
    "from openinference.instrumentation import using_session\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "from opentelemetry import trace\n",
    "\n",
    "client = genai.GenerativeModel(\"gemini-2.0-flash-001\")\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "@tracer.start_as_current_span(name=\"agent\", attributes={SpanAttributes.OPENINFERENCE_SPAN_KIND: \"agent\"})\n",
    "def assistant(\n",
    "  messages: list[dict],\n",
    "  session_id: str = str,\n",
    "):\n",
    "  current_span = trace.get_current_span()\n",
    "  current_span.set_attribute(SpanAttributes.SESSION_ID, session_id)\n",
    "  current_span.set_attribute(SpanAttributes.INPUT_VALUE, messages[-1].get('content'))\n",
    "\n",
    "  # Propagate the session_id down to spans crated by the OpenAI instrumentation\n",
    "  # This is not strictly necessary, but it helps to correlate the spans to the same session\n",
    "  with using_session(session_id):\n",
    "   response = client.chat.completions.create(\n",
    "       model=\"gpt-3.5-turbo\",\n",
    "       messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}] + messages,\n",
    "   ).choices[0].message\n",
    "\n",
    "  current_span.set_attribute(SpanAttributes.OUTPUT_VALUE, response.content)\n",
    "  return response\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": \"hi! im bob\"}\n",
    "]\n",
    "response = assistant(\n",
    "  messages,\n",
    "  session_id=session_id,\n",
    ")\n",
    "messages = messages + [\n",
    "  response,\n",
    "  {\"role\": \"user\", \"content\": \"what's my name?\"}\n",
    "]\n",
    "response = assistant(\n",
    "  messages,\n",
    "  session_id=session_id,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
